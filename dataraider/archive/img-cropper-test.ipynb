{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import batch_img_cropper as img_cropper\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "3\n",
      "136\n",
      "length of image: 652\n",
      "for 1, region_start: 244, region_end: 380\n",
      "[204, 300]\n",
      "for 2, region_start: 380, region_end: 516\n",
      "[204, 300, 516]\n"
     ]
    }
   ],
   "source": [
    "image_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/TF_to_json/TEST/\"\n",
    "image_name = \"RSC18_table_1\"\n",
    "image_path = os.path.join(image_directory, f\"{image_name}.png\")\n",
    "output_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/TF_to_json/\"\n",
    "min_segment_height = 150\n",
    "threshold=254.5\n",
    "percentage_threshold = 0.995\n",
    "step_size = 10\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "region_start_1 = int(1/4 * len(image))\n",
    "region_start_2 = int(3/8 * len(image))\n",
    "first_split_line = img_cropper.find_last_line(image, threshold=254.8, region_start=region_start_1, region_end=region_start_2, percentage_threshold= 0.995, step_size = 10)\n",
    "remaining_height = image.shape[0] - region_start_2\n",
    "print(remaining_height)\n",
    "num_segments = math.ceil(remaining_height / min_segment_height)\n",
    "print(num_segments)\n",
    "segment_height = remaining_height // num_segments\n",
    "print(segment_height)\n",
    "print(f\"length of image: {image.shape[0]}\")\n",
    "\n",
    "split_lines = [first_split_line]\n",
    "region_start_list = [region_start_2]\n",
    "for i in range(1, num_segments):\n",
    "    region_start = region_start_list[-1]\n",
    "    region_end = region_start + segment_height\n",
    "    region_start_list.append(region_end)\n",
    "    print(f\"for {i}, region_start: {region_start}, region_end: {region_end}\")\n",
    "\n",
    "    split_line = img_cropper.find_last_line(image, threshold, region_start, region_end, percentage_threshold, step_size)\n",
    "    split_lines.append(split_line)\n",
    "    print(split_lines)\n",
    "\n",
    "segments = img_cropper.crop_image(image, split_lines)\n",
    "for idx, segment in enumerate(segments):\n",
    "    cv2.imwrite(os.path.join(output_directory, f\"{image_name}_{idx+1}.png\"), segment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "my_list = [1, 2, 3]\n",
    "new_elements = [4,5,6]\n",
    "my_list.extend(new_elements)\n",
    "print(my_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
