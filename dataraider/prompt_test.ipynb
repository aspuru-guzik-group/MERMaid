{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test photocatalysis reaction prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "import json\n",
    "import glob\n",
    "import requests\n",
    "import math \n",
    "\n",
    "prompt_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/prompts/\"\n",
    "image_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/org_syn/relevant_images/\"\n",
    "json_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/org_syn/jsons/\"\n",
    "cropped_image_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/org_syn/cropped_images/\"\n",
    "get_data_prompt = \"org_syn_get_data_prompt_v2\"\n",
    "update_dict_prompt = \"org_syn_update_dict_prompt\"\n",
    "api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path): \n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def reformat_json(input_file):\n",
    "    \"\"\"\n",
    "    Clean and format JSON data by removing unwanted characters and ensuring proper JSON formatting\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r') as file:\n",
    "        json_content = file.read()\n",
    "        json_content = json_content.replace(\"\\\"```json\\\\n\", '').replace('```\"', '').strip()       \n",
    "        json_content = json_content.replace('\\\\n', '').replace('\\\\\"', '\"')\n",
    "        data = json.loads(json_content)\n",
    "        formatted_json = json.dumps(data, indent=4)\n",
    "\n",
    "    # Write the formatted JSON to the output file\n",
    "    with open(input_file, 'w') as file:\n",
    "        file.write(formatted_json)\n",
    "\n",
    "def adaptive_get_data(api_key, prompt_directory, get_data_prompt, image_name, image_directory, json_directory):\n",
    "    # Get all subfigures files \n",
    "    image_paths = glob.glob(os.path.join(image_directory, f\"{image_name}_*.png\"))\n",
    "    if not image_paths:\n",
    "        print(f\"No subimages found for {image_name}\")\n",
    "        return\n",
    "\n",
    "    base64_images = [encode_image(image_path) for image_path in image_paths]\n",
    "\n",
    "    # Get user prompt file\n",
    "    user_prompt_path = os.path.join(prompt_directory, f\"{get_data_prompt}.txt\")\n",
    "    with open(user_prompt_path, \"r\") as file:\n",
    "        user_message = file.read().strip()\n",
    "\n",
    "    # Get image captions and response file paths\n",
    "    image_caption_path = os.path.join(image_directory, f\"{image_name}.txt\")\n",
    "    response_path = os.path.join(json_directory, f\"{image_name}_response.json\")\n",
    "    token_path = os.path.join(f\"{json_directory}/token_count/\", f\"{image_name}_tokencount.json\") # token count is saved in a subfolder in json_directory\n",
    "\n",
    "    # Create base message\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"text\", \"text\": user_message}]\n",
    "    }]\n",
    "\n",
    "    # Add each encoded image as a separate entry\n",
    "    messages[0][\"content\"].extend({\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "    } for base64_image in base64_images)\n",
    "    \n",
    "    # If the image caption file exists, append it to the messages content\n",
    "    if os.path.exists(image_caption_path):\n",
    "        with open(image_caption_path, \"r\") as file:\n",
    "            image_caption = file.read().strip()\n",
    "        messages[0][\"content\"].append({\"type\": \"text\",\"text\": image_caption})\n",
    "        print('Caption appended!')\n",
    "    else: \n",
    "        print('No caption found!')\n",
    "\n",
    "    # API request headers and payload\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-2024-08-06\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 4000\n",
    "    }\n",
    "\n",
    "    # Send API request\n",
    "    try:\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise error if the request failed\n",
    "        reaction_data = response.json()['choices'][0]['message']['content']\n",
    "        token_count = response.json()['usage']\n",
    "\n",
    "        # Save responses\n",
    "        with open(response_path, 'w') as json_file:\n",
    "            json.dump(reaction_data, json_file)\n",
    "        print(f\"Reaction data saved to {response_path}!\")\n",
    "\n",
    "        with open(token_path, 'w') as token_file: \n",
    "            json.dump(token_count, token_file)\n",
    "        print(f\"Token count saved to {response_path}!\")\n",
    "\n",
    "        # Clean response: \n",
    "        try: \n",
    "            reformat_json(response_path)\n",
    "            print(f\"{response_path}: Reaction data cleaned.\")\n",
    "\n",
    "        except Exception as e: \n",
    "            print(f\"{response_path}: Reaction data not cleaned. Error: {e}\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during API request: {e}\")\n",
    "\n",
    "def update_dict(api_key, prompt_directory, update_dict_prompt, json_file, json_directory):\n",
    "    \n",
    "    # Get user prompt file\n",
    "    user_prompt_path = os.path.join(prompt_directory, f\"{update_dict_prompt}.txt\")\n",
    "    with open(user_prompt_path, \"r\") as file:\n",
    "        user_message = file.read().strip()\n",
    "    \n",
    "    # Get Json file\n",
    "    json_path = os.path.join(json_directory, f\"{json_file}.json\")\n",
    "    with open(json_path, \"r\") as file2:\n",
    "        json_dict = file2.read().strip()\n",
    "\n",
    "    # Get response paths\n",
    "    response_path = os.path.join(json_directory, f\"{json_file}_updated.json\")\n",
    "    token_path = os.path.join(f\"{json_directory}/token_count/\", f\"{json_file}_updated_tokencount.json\")\n",
    "\n",
    "    # Construct message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_message\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": json_dict\n",
    "                }              \n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # API request headers and payload\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-2024-08-06\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 4096\n",
    "    }\n",
    "\n",
    "    # Send API request\n",
    "    try:\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response.raise_for_status()  # Raise error if the request failed\n",
    "        reaction_data = response.json()['choices'][0]['message']['content']\n",
    "        token_count = response.json()['usage']\n",
    "\n",
    "        # Save response\n",
    "        with open(response_path, 'w') as json_file:\n",
    "            json.dump(reaction_data, json_file)\n",
    "\n",
    "        print(f\"Reaction data saved to {response_path}!\")\n",
    "\n",
    "        with open(token_path,'w') as token_file:\n",
    "            json.dump(token_count, token_file)\n",
    "\n",
    "        print(f\"Token count saved to {token_path}!\")\n",
    "        \n",
    "        # Clean response\n",
    "        try:\n",
    "            reformat_json(response_path)\n",
    "            print(f\"{response_path}: Reaction data cleaned.\")\n",
    "        except Exception as e:\n",
    "            print(f\"{response_path}: Reaction data not cleaned.Error: {e}\")\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error during API request: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction data saved to /mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/org_syn/jsons/d4ra04674a_page_2_table_0_response_updated.json!\n",
      "Token count saved to /mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/org_syn/jsons/d4ra04674a_page_2_table_0_response_updated_tokencount.json!\n",
      "/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/org_syn/jsons/d4ra04674a_page_2_table_0_response_updated.json: Reaction data cleaned.\n"
     ]
    }
   ],
   "source": [
    "image_name = \"d4ra04674a_page_2_table_0\"\n",
    "#image_name = \"d3gc02735j_page_2_table_0\"\n",
    "json_file = os.path.join(json_directory, f\"{image_name}_response\")\n",
    "\n",
    "#adaptive_get_data(api_key, prompt_directory, get_data_prompt, image_name, cropped_image_directory, json_directory)\n",
    "# #reformat_json(json_file)\n",
    "update_dict(api_key, prompt_directory, update_dict_prompt, json_file, json_directory)\n",
    "\n",
    "\n",
    "# # Batch \n",
    "# failed_images = []\n",
    "\n",
    "# for file in os.listdir(image_directory):\n",
    "#     if (file.endswith(\".png\")):\n",
    "#         try: \n",
    "#             image_name = file.removesuffix('.png')\n",
    "#             adaptive_get_data(api_key, prompt_directory, get_data_prompt, image_name, cropped_image_directory, json_directory)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing image: {file}, Error: {e}\")\n",
    "#             failed_images.append(file)\n",
    "\n",
    "# # for file in os.listdir(json_directory):\n",
    "# #     if (file.endswith(\".json\")):\n",
    "# #         try: \n",
    "# #             json_name = file.removesuffix('.json')\n",
    "# #             update_dict(api_key, prompt_directory, update_dict_prompt, json_name, json_directory)\n",
    "# #         except Exception as e:\n",
    "# #             print(f\"Error processing JSON: {file}, Error: {e}\")\n",
    "# #             failed_images.append(file)\n",
    "\n",
    "# if failed_images:\n",
    "#     print(\"Failed images:\")\n",
    "#     for failed in failed_images:\n",
    "#         print(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(image_directory):\n",
    "    image_name = file.removesuffix('.png')\n",
    "    print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image_name, image_directory, cropped_image_directory, min_segment_height=120): \n",
    "    \"\"\"\n",
    "    Adaptively crop a given figure into smaller subfigures before passing to VLM based on image length\n",
    "\n",
    "    parameters: \n",
    "    image_name: base image name\n",
    "    image_directory: root directory where original images are saved \n",
    "    cropped_image_directory: output directory to save cropped images \n",
    "    min_segment_height: minimum height of each segmented subfigure\n",
    "    \"\"\"\n",
    "    def find_split_line(image, threshold, region_start, region_end, percentage_threshold, step_size):\n",
    "        \"\"\"\n",
    "        Helper function to determine where to segment the figure\n",
    "        \"\"\"\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Convert the image to grayscale            \n",
    "        _, thresh = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY) # Identify white pixels\n",
    "        white_pixel_count = np.count_nonzero(thresh == 255, axis=1) \n",
    "\n",
    "        # Find the last line with >= the specified percentage of white pixels in the specified region\n",
    "        split_line = region_end\n",
    "        while split_line > region_start:\n",
    "            min_white_pixels = int(percentage_threshold * len(thresh[split_line]))\n",
    "\n",
    "            if white_pixel_count[split_line] >= min_white_pixels:\n",
    "                break\n",
    "            split_line -= step_size\n",
    "\n",
    "        return split_line if split_line > region_start else region_start\n",
    "\n",
    "    def adaptive_split_lines(image, first_split_line, min_segment_height, threshold, percentage_threshold, step_size):\n",
    "        \"\"\"\n",
    "        Helper function to identify all the split lines for an image\n",
    "        \"\"\"\n",
    "        \n",
    "        # Calculate the remaining height after the first split line\n",
    "        first_region_end = int(3/8 *len(image))\n",
    "        remaining_height = image.shape[0] - first_region_end\n",
    "        num_segments = math.ceil(remaining_height / min_segment_height)\n",
    "        segment_height = remaining_height // num_segments  # Determine the approximate height of each segment\n",
    "\n",
    "        split_lines = [first_split_line]  # Start with the first fixed split line\n",
    "        region_start_list = [first_region_end] \n",
    "\n",
    "        for i in range(1, num_segments):\n",
    "            # Calculate dynamic region start and end for each segment\n",
    "            region_start = region_start_list[-1]\n",
    "            region_end = region_start + segment_height\n",
    "            region_start_list.append(region_end)\n",
    "\n",
    "            # Find the split line for the current region\n",
    "            split_line = find_split_line(image, threshold, region_start, region_end, percentage_threshold, step_size)\n",
    "            split_lines.append(split_line)\n",
    "\n",
    "        return split_lines\n",
    "    \n",
    "    def segment_image(image, split_lines):\n",
    "        \"\"\"\n",
    "        Helper function to crop image based on split lines\n",
    "        \"\"\"\n",
    "        segments = []\n",
    "        prev_line = 0\n",
    "\n",
    "        for split_line in split_lines:\n",
    "            segments.append(image[prev_line:split_line, :])\n",
    "            prev_line = split_line\n",
    "\n",
    "        segments.append(image[prev_line:, :]) # Add the final segment (from the last split line to the end of the image)\n",
    "\n",
    "        return segments\n",
    "    \n",
    "    image_path = os.path.join(image_directory, f\"{image_name}.png\")\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Error: Image {image_name}.png not found.\")\n",
    "        return\n",
    "    \n",
    "    # Set parameters\n",
    "    threshold = 254.8\n",
    "    percentage_threshold = 0.995\n",
    "    step_size = 10\n",
    "\n",
    "    # Find the first split line within the first 1/4 of the image (usually the reaction diagram)\n",
    "    region_start_1 = int(1/4 * len(image))\n",
    "    region_end_1 = int(3/8 *len(image))\n",
    "    first_split_line = find_split_line(image, threshold, region_start_1, region_end_1, percentage_threshold, step_size)\n",
    "\n",
    "    try: \n",
    "        # Find adaptive split lines based on the remaining height after the first split line\n",
    "        split_lines = adaptive_split_lines(image, first_split_line, min_segment_height, threshold, percentage_threshold, step_size)\n",
    "\n",
    "        # Check if split lines are valid\n",
    "        if len(split_lines) < 1:\n",
    "            raise ValueError(f\"Error: Unable to find valid split lines for {image_name}. Saving original image.\")\n",
    "\n",
    "        # Crop the image into segments\n",
    "        segments = segment_image(image, split_lines)\n",
    "\n",
    "        # Check if cropped segments have valid size\n",
    "        valid_segments = 0\n",
    "        for idx, segment in enumerate(segments): \n",
    "            if segment.size > 0:\n",
    "                cv2.imwrite(os.path.join(cropped_image_directory, f\"{image_name}_{idx+1}.png\"), segment)\n",
    "                valid_segments += 1\n",
    "            else: \n",
    "                print(f\"Warning: Segment {idx+1} of {image_name} has zero size. Skipping.\")\n",
    "        \n",
    "        if valid_segments == 0:\n",
    "            raise ValueError(f\"Error: No valid segments for {image_name}. Saving original image.\")\n",
    "\n",
    "    except Exception as e: \n",
    "        print(str(e))\n",
    "        cv2.imwrite(os.path.join(cropped_image_directory, f\"{image_name}_original.png\"), image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_name = \"1-s2.0-S2666554924000966-main_page_4_table_1\"\n",
    "\n",
    "for image in os.listdir(image_directory): \n",
    "    image_name = image.removesuffix(\".png\")\n",
    "    crop_image(image_name, image_directory, cropped_image_directory, min_segment_height = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict_with_smiles(image_name, json_directory): \n",
    "        \"\"\"\n",
    "        Combine reaction dictionary with reaction SMILES\n",
    "        \"\"\"\n",
    "        # load optimization runs dictionary \n",
    "        dict_path = os.path.join(json_directory, f\"{image_name}_response_updated.json\")\n",
    "        with open(dict_path, \"r\") as file:\n",
    "            opt_dict = json.load(file)\n",
    "        opt_data = opt_dict[\"Optimization Runs\"]\n",
    "\n",
    "        # load reaction smiles list\n",
    "        smiles_path = os.path.join(json_directory, f\"{image_name}_rxnsmiles.json\")\n",
    "        with open(smiles_path, \"r\") as file2: \n",
    "            smiles_list = json.load(file2)\n",
    "\n",
    "        if not smiles_list or 'NR' in smiles_list[0].get('reactants', '') or 'NR' in smiles_list[0].get('products', ''):\n",
    "            reactants = 'NR' if not smiles_list or 'NR' in smiles_list[0].get('reactants', '') else smiles_list[0]['reactants']\n",
    "            products = 'NR' if not smiles_list or 'NR' in smiles_list[0].get('products', '') else smiles_list[0]['products']\n",
    "        else:\n",
    "            reactants = smiles_list[0].get('reactants', 'NR')\n",
    "            products = smiles_list[0].get('products', 'NR')\n",
    "\n",
    "        # Combine and save\n",
    "        updated_dict = {\n",
    "            \"SMILES\": {\n",
    "                \"reactants\": reactants, \n",
    "                \"products\": products\n",
    "            }, \n",
    "            \"Optimization Runs\": opt_data\n",
    "        }\n",
    "\n",
    "        output_path = os.path.join(json_directory, f\"{image_name}_full_opt_dictionary.json\")\n",
    "        with open(output_path, 'w') as output_file: \n",
    "            json.dump(updated_dict, output_file, indent = 4)\n",
    "\n",
    "        print (f\"Reaction optimization dictionary updated with reaction smiles for {image_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reaction optimization dictionary updated with reaction smiles for RSC10_table_1\n",
      "Reaction optimization dictionary updated with reaction smiles for RSC18_table_1\n",
      "Reaction optimization dictionary updated with reaction smiles for RSC2_table_1\n",
      "Reaction optimization dictionary updated with reaction smiles for wiley17_table_1\n",
      "Reaction optimization dictionary updated with reaction smiles for wiley26_table_1\n",
      "Reaction optimization dictionary updated with reaction smiles for wiley37_table_1\n"
     ]
    }
   ],
   "source": [
    "json_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/electrosynthesis/json_responses_no SMILES/\"\n",
    "image_directory = \"/mnt/c/Users/Shi Xuan/OneDrive - University of Toronto/Project_MERLIN/Project_Digital esyn corpus/manuscript preparation/datasets/electrosynthesis/\"\n",
    "\n",
    "for image in os.listdir(image_directory):\n",
    "    if image.endswith(\".png\"): \n",
    "        image_name = image.removesuffix(\".png\")\n",
    "        try: \n",
    "            update_dict_with_smiles(image_name, json_directory)\n",
    "        except Exception as e:\n",
    "            print(f\"error {e} for {image_name}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
